services:
  generator:
    container_name: generator
    build: generator/

  airflow-webserver:
    container_name: airflow-webserver
    image: apache/airflow:latest
    environment:
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://$AIRFLOW_POSTGRES_USERNAME:$AIRFLOW_POSTGRES_PASSWORD@airflow-postgres:5432/$AIRFLOW_POSTGRES_DB
      - AIRFLOW__WEBSERVER__SECRET_KEY=$AIRFLOW_WEBSERVER_SECRET_KEY
      - AIRFLOW__CORE__EXECUTOR=CeleryExecutor
      - AIRFLOW__CELERY__BROKER_URL=redis://:@redis:6379/0
      - _PIP_ADDITIONAL_REQUIREMENTS=${_PIP_ADDITIONAL_REQUIREMENTS:- apache-airflow-providers-apache-kafka}
      - AIWFLOW_VAR_KAFKA_TOPIC_PERSON=$KAFKA_TOPIC_PERSON
    volumes:
      - ./airflow-dags:/opt/airflow/dags
    ports:
      - $AIRFLOW_WEBSERVER_PORT:8080
    command: >
      bash -c "
        if ! airflow db check > /dev/null 2>&1; then
          airflow db init
        fi &&
        if ! airflow users list | grep -q $AIRFLOW_USERNAME; then
          airflow users create --username $AIRFLOW_USERNAME --firstname Admin --lastname User --role Admin --email admin@example.com --password $AIRFLOW_PASSWORD
        fi &&
        airflow webserver
      "
    depends_on:
      - airflow-postgres
      - airflow-scheduler
      - airflow-redis
      - generator
      - kafka-broker

  airflow-scheduler:
    container_name: airflow-scheduler
    image: apache/airflow:latest
    environment:
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://$AIRFLOW_POSTGRES_USERNAME:$AIRFLOW_POSTGRES_PASSWORD@airflow-postgres:5432/$AIRFLOW_POSTGRES_DB
      - AIRFLOW__WEBSERVER__SECRET_KEY=$AIRFLOW_WEBSERVER_SECRET_KEY
      - _PIP_ADDITIONAL_REQUIREMENTS=${_PIP_ADDITIONAL_REQUIREMENTS:- apache-airflow-providers-apache-kafka}
      - AIRFLOW_VAR_KAFKA_TOPIC=$KAFKA_TOPIC_PERSON
    volumes:
      - ./airflow-dags:/opt/airflow/dags
    command: airflow scheduler
    depends_on:
      - airflow-postgres

  airflow-postgres:
    container_name: airflow-postgres
    image: postgres:latest
    environment:
      - POSTGRES_USER=$AIRFLOW_POSTGRES_USERNAME
      - POSTGRES_PASSWORD=$AIRFLOW_POSTGRES_PASSWORD
      - POSTGRES_DB=$AIRFLOW_POSTGRES_DB
    volumes: 
      - postgres-data:/var/lib/postgresql/data

  airflow-redis:
    container_name: airflow-redis
    image: redis:latest
  
  kafka-console:
    container_name: kafka-console
    image: redpandadata/console:latest
    ports:
      - $KAFKA_CONSOLE_PORT:8080
    environment:
      - KAFKA_BROKERS=kafka-broker:29092
    depends_on:
      - kafka-broker

  kafka-broker:
    container_name: kafka-broker
    image: confluentinc/cp-kafka:latest
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: kafka-zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-broker:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    depends_on:
      - kafka-zookeeper

  kafka-zookeeper:
    container_name: kafka-zookeeper
    image: confluentinc/cp-zookeeper:latest
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  kafka-init:
    container_name: kafka-init
    image: confluentinc/cp-kafka:latest
    entrypoint: [ '/bin/sh', '-c' ]
    command: |
      "
      # blocks until kafka is reachable
      kafka-topics --bootstrap-server kafka-broker:29092 --list

      echo -e 'Creating kafka topics'
      kafka-topics --bootstrap-server kafka-broker:29092 --create --if-not-exists --topic $KAFKA_TOPIC_PERSON --replication-factor 1 --partitions 1

      echo -e 'Successfully created the following topics:'
      kafka-topics --bootstrap-server kafka-broker:29092 --list
      "
    depends_on:
      - kafka-broker

volumes:
  postgres-data: