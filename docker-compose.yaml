services:
  generator:
    container_name: generator
    build: generator/

  airflow-webserver:
    container_name: airflow-webserver
    image: apache/airflow:latest
    environment:
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://$AIRFLOW_POSTGRES_USERNAME:$AIRFLOW_POSTGRES_PASSWORD@airflow-postgres:5432/$AIRFLOW_POSTGRES_DB
      - AIRFLOW__WEBSERVER__SECRET_KEY=$AIRFLOW_WEBSERVER_SECRET_KEY
      - AIRFLOW__CORE__EXECUTOR=CeleryExecutor
      - AIRFLOW__CELERY__BROKER_URL=redis://:@redis:6379/0
      - _PIP_ADDITIONAL_REQUIREMENTS=${_PIP_ADDITIONAL_REQUIREMENTS:- apache-airflow-providers-apache-kafka}
      - AIWFLOW_VAR_KAFKA_TOPIC_PERSON=$KAFKA_TOPIC_PERSON
    volumes:
      - ./airflow-dags:/opt/airflow/dags
    ports:
      - $AIRFLOW_WEBSERVER_PORT:8080
    command: >
      bash -c "
        airflow db init &&
        if ! airflow users list | grep -q $AIRFLOW_USERNAME; then
          airflow users create --username $AIRFLOW_USERNAME --firstname Admin --lastname User --role Admin --email admin@example.com --password $AIRFLOW_PASSWORD
        fi &&
        airflow webserver
      "
    depends_on:
      - airflow-postgres
      - airflow-scheduler
      - airflow-redis
      - generator
      - kafka-broker

  airflow-scheduler:
    container_name: airflow-scheduler
    image: apache/airflow:latest
    environment:
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://$AIRFLOW_POSTGRES_USERNAME:$AIRFLOW_POSTGRES_PASSWORD@airflow-postgres:5432/$AIRFLOW_POSTGRES_DB
      - AIRFLOW__WEBSERVER__SECRET_KEY=$AIRFLOW_WEBSERVER_SECRET_KEY
      - _PIP_ADDITIONAL_REQUIREMENTS=${_PIP_ADDITIONAL_REQUIREMENTS:- apache-airflow-providers-apache-kafka}
      - AIRFLOW_VAR_KAFKA_TOPIC=$KAFKA_TOPIC_PERSON
    volumes:
      - ./airflow-dags:/opt/airflow/dags
    command: airflow scheduler
    depends_on:
      - airflow-postgres

  airflow-postgres:
    container_name: airflow-postgres
    image: postgres:latest
    environment:
      - POSTGRES_USER=$AIRFLOW_POSTGRES_USERNAME
      - POSTGRES_PASSWORD=$AIRFLOW_POSTGRES_PASSWORD
      - POSTGRES_DB=$AIRFLOW_POSTGRES_DB

  airflow-redis:
    container_name: airflow-redis
    image: redis:latest
  
  kafka-console:
    container_name: kafka-console
    image: redpandadata/console:latest
    ports:
      - $KAFKA_CONSOLE_PORT:8080
    environment:
      - KAFKA_BROKERS=kafka-broker:29092
    depends_on:
      - kafka-broker

  kafka-broker:
    container_name: kafka-broker
    image: confluentinc/cp-kafka:latest
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: kafka-zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-broker:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
    depends_on:
      - kafka-zookeeper

  kafka-zookeeper:
    container_name: kafka-zookeeper
    image: confluentinc/cp-zookeeper:latest
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  kafka-init:
    container_name: kafka-init
    image: confluentinc/cp-kafka:latest
    entrypoint: [ '/bin/sh', '-c' ]
    command: |
      "
      # blocks until kafka is reachable
      kafka-topics --bootstrap-server kafka-broker:29092 --list

      echo -e 'Creating kafka topics'
      kafka-topics --bootstrap-server kafka-broker:29092 --create --if-not-exists --topic $KAFKA_TOPIC_PERSON --replication-factor 1 --partitions 1
    
      echo -e 'Successfully created the following topics:'
      kafka-topics --bootstrap-server kafka-broker:29092 --list
      "
    depends_on:
      - kafka-broker

  ksqldb-server:
    container_name: ksqldb-server
    image: confluentinc/cp-ksqldb-server:latest
    hostname: ksqldb-server
    healthcheck:
      test: curl -f http://ksqldb-server:8088/ || exit 1
    environment:
      KSQL_LISTENERS: http://0.0.0.0:8088
      KSQL_BOOTSTRAP_SERVERS: kafka-broker:29092
      KSQL_KSQL_LOGGING_PROCESSING_STREAM_AUTO_CREATE: "true"
      KSQL_KSQL_LOGGING_PROCESSING_TOPIC_AUTO_CREATE: "true"
    depends_on:
      - kafka-broker

  ksqldb-init-scripts:
    container_name: ksqldb-init-scripts
    image: confluentinc/cp-ksqldb-cli:latest
    entrypoint: [ '/bin/sh', '-c' ]
    command: |
      "
      echo -e 'Creating ksqlDB streams and tables'
      ls -ltr '/scripts/';
      ksql http://ksqldb-server:8088 <<EOF
      RUN SCRIPT '/scripts/ksqldb-init.sql';
      EOF
      "
    volumes:
      - ./ksql-scripts/:/scripts/
    depends_on:
      ksqldb-server:
        condition: service_healthy

  # docker exec -it ksqldb-cli ksql http://ksqldb-server:8088
  ksqldb-cli:
    container_name: ksqldb-cli
    image: confluentinc/cp-ksqldb-cli:latest
    entrypoint: /bin/sh
    tty: true
    depends_on:
      - kafka-broker
      - ksqldb-server
